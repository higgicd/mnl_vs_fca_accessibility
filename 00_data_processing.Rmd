---
title: "Workbook 00: Data Processing"
output: html_notebook
---

```{r, include = FALSE}
library(cancensus)
library(magrittr)
library(osmextract)
library(r5r)
library(sf)
library(smoothr)
library(tidyverse)
library(tidytransit)
library(tmap)

# options
tmap_mode("plot")
options(cancensus.api_key = "CensusMapper_8a670a7173437cf3e6db57b780ae14bf")
options(java.parameters = "-Xmx8G")
dir.create("./results")
dir.create("./r5_graph") # for the r5 network graph
r5_path <- file.path("./r5_graph")
```

# Prepare Input Data
## Retreive Census Data

```{r get harbour data, eval = FALSE}
# you can just load a pre-prepared file in the next code chunk
# download hamilton harbour water file
download.file(url = "http://www12.statcan.gc.ca/census-recensement/2011/geo/bound-limit/files-fichiers/2016/lhy_000c16a_e.zip", 
              destfile = "./data/lhy_000c16a_e.zip")

unzip(zipfile = "./data/lhy_000c16a_e.zip", exdir = "./data")

hamilton_harbour <- st_read("./data/lhy_000c16a_e.shp") %>%
  filter(NAME == "Hamilton Harbour" | NAME == "Desjardins Canal") %>%
  # project to NAD 1983 Zone 17N
  st_transform(crs = 26917)

# save for future use
save(hamilton_harbour, file = "./data/hamilton_harbour.RData", compress = "xz")
```

```{r get census 2016 data, include = FALSE}
load("./data/hamilton_harbour.RData")

data_da_2016_poly <- get_census(dataset='CA16', regions=list(CSD="3525005"), #35537
                          level='DA', use_cache = FALSE, geo_format = 'sf') %>%
  # project to NAD 1983 Zone 17N
  st_transform(crs = 26917)

data_da_2016_poly <- st_difference(data_da_2016_poly, st_union(st_combine(hamilton_harbour %>% filter(NAME == "Hamilton Harbour")))) %>% 
  drop_crumbs(threshold = 1) %>%
  mutate(popdens = Population / (st_area(.)/10000)) # population density in people/ha

data_da_2016_point <- data_da_2016_poly %>% st_centroid()

# get province for background
ontario_poly <- get_census(dataset='CA16', regions=list(PR=c("35")),
                          level='Regions', use_cache = FALSE, geo_format = 'sf') %>%
  # project to NAD 1983 Zone 17N
  st_transform(crs = 26917) %>%
  st_difference(., st_union(st_combine(hamilton_harbour %>% filter(NAME == "Hamilton Harbour")))) %>% 
  drop_crumbs(threshold = 1)
```

## Load Physician Data

```{r}
doctors <- read.csv("./data/HamiltonDoctors.csv") %>% 
  st_as_sf(coords = c("Longitude", "Latitude"), crs = 4326) %>%
  rename(doctor_id = ID, doctor_count = Sum_count)
```

## Maps of Input Data

```{r}
tm_shape(ontario_poly, bbox = st_bbox(data_da_2016_poly)) + 
  tm_fill("grey90") +
  tm_shape(data_da_2016_poly) + 
  tm_fill(col = "popdens", palette = "viridis", style = "jenks", title = "Population per HA")  +
  tm_layout(legend.position = c("left","bottom"))

tm_shape(ontario_poly, bbox = st_bbox(data_da_2016_poly)) + 
  tm_fill("grey90") +
  tm_shape(data_da_2016_poly) + 
  tm_fill("grey75") +
  tm_shape(doctors) + 
  tm_bubbles(size = "doctor_count", 
             col = "doctor_count", 
             palette = "viridis", 
             style = "jenks", 
             title.size = "Family Physicians", 
             title.col = "") +
  tm_layout(legend.position = c("left","bottom"))
```

# Get Travel Time Matrix
## Download Travel Network Data

First, get data from OpenStreetMap for the Greater Golden Horseshoe region:

```{r osm extract, include - FALSE}
# get url
#oe_match("Golden Horseshoe")

# download osm
oe_download(file_url = "http://download.openstreetmap.fr/extracts/north-america/canada/ontario/golden_horseshoe-latest.osm.pbf", 
            provider = "openstreetmap_fr",
            download_directory = "./r5_graph")

# read in as sf if you want
#osm <- oe_read(file_path = "./data/openstreetmap_fr_golden_horseshoe-latest.osm.pbf", layer = "lines")
```

And General Transit Feed Specification (GTFS) files for the HSR:

```{r download gtfs, include = FALSE, eval = FALSE}
download.file(url = "https://transitfeeds.com/p/hamilton-street-railway/31/latest/download", 
              destfile = file.path(r5_path, "hsr.zip"), mode = "wb")
```

## Build Network
Now build the network:

```{r build graph, include = FALSE}
r5_network <- setup_r5(data_path = r5_path, verbose = FALSE)
```

## Set Up Routing
Set up the departure date and time:

```{r get calendar range of GTFS}
# query the gtfs file using tidytransit
hsr_gtfs <- read_gtfs(path = file.path(r5_path, "hsr.zip"))
summary(hsr_gtfs)

# set departure datetime within the calendar range of the GTFS (to use transit)
departure_datetime <- as.POSIXct("2021-06-29 08:00:00", 
                                 format = "%Y-%m-%d %H:%M:%S",
                                 tz = "America/New_York")
```

Prepare origins and destinations:

```{r prepare origins and destinations, warning = FALSE}
# origins
origins_i <-  data_da_2016_point %>% 
  filter(Population >0) %>%
  transmute(id = GeoUID, geometry) %>% 
  st_centroid() %>%
  st_transform(nyc_cb_point, crs = 4326)

# analyses revealed a problem with network snapping for this DA
# so let's manually alter its coordinates to better locate around some roads
st_geometry(origins_i[origins_i$id == "35250986", ]) <-  st_sfc(st_point(c(-79.987629, 43.263348)))

# destinations
destinations_j <-  doctors %>% 
  transmute(id = doctor_id, geometry) %>%
  st_centroid() %>%
  st_transform(nyc_cb_point, crs = 4326)
```

## Calculate Travel Time Matrix
Now calculate the travel time matrix:

```{r}
ttm <- travel_time_matrix(r5r_core = r5_network,
                          origins = origins_i,
                          destinations = destinations_j,
                          mode = c("CAR"),
                          departure_datetime = departure_datetime,
                          max_trip_duration = 300, verbose = FALSE)
```

# Save

```{r}
save(data_da_2016_poly, doctors, ontario_poly, ttm, 
     file = "./results/output_workbook_00.RData", compress = TRUE)
```
